---
title: "AR model with texting"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache = TRUE)

library(here)
library(rstan)
library(dplyr)
library(ggplot2)
library(digest)
library(purrr)
library(aws.s3)
library(aws.ec2metadata)
library(aws.signature)
library(shinystan)
library(bayesplot)
library(stringr)
library(gridExtra)

util <- new.env()
source(here('src', 'codebase', 'stan_utility.R'), local=util)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
colors <- list(c_light=c("#DCBCBC"), c_light_highlight=c("#C79999"),
               c_mid=c("#B97C7C"),   c_mid_highlight=c("#A25050"),
               c_dark=c("#8F2727"),  c_dark_highlight=c("#7C0000"),
               d_light=c("#BCBCDC"), d_light_highlight=c("#9999C7"),
               d_mid=c("#7C7CB9"),   d_mid_highlight=c("#5050A2"),
               d_dark=c("#27278F"),  d_dark_highlight=c("#00007c"))
```

## Data prep
```{r init_data}
subject <- here::here("data") %>% 
  dir() %>% 
  stringr::str_match('T[0-9]{3}') %>% 
  purrr::discard(is.na)
file_paths <- purrr::map(
  subject,  function(file_name) c(
    here::here("data", paste(file_name, ".csv", sep=""))))
subject_bio <- readxl::read_excel(
  here::here("etc", "Dataset-Table-Index.xlsx")) %>% 
  dplyr::filter(stringr::str_detect(Subject, 'T[0-9]{3}')) %>% 
  dplyr::filter(!is.na(Gender)) %>%
  dplyr::select(subject=Subject, gender=Gender, age_group=`Age Group`)
tp_files <- dir(here::here("structured_study_data"),
                pattern="*.tp", recursive=TRUE, full.names=TRUE)
tp_subjects <- stringr::str_match(tp_files, "(T[0-9]{3}).tp")[, 2]
tp_data <- purrr::map(tp_files, readLines, warn=FALSE) %>%
    purrr::set_names(tp_subjects) %>%
    dplyr::bind_rows(.id="subject") %>%
    tidyr::gather(subject, personality)
tai_data <- tp_data %>% 
    dplyr::filter(stringr::str_detect(personality, 'TAI')) %>%
    dplyr::mutate(tai=as.numeric(stringr::str_replace(personality, "TAI:", ""))) %>%
    dplyr::select(-personality)
typeab_data <- tp_data %>% 
    dplyr::filter(stringr::str_detect(personality, 'Type AB:')) %>%
    dplyr::mutate(type_ab=as.numeric(stringr::str_replace(personality, "Type AB:", ""))) %>%
    dplyr::select(-personality)
psych_df <- dplyr::inner_join(tai_data, typeab_data, by="subject")
rm(tp_files, tp_subjects, tp_data, tai_data, typeab_data)    
df <- purrr::map(file_paths, read.csv) %>% 
    purrr::set_names(subject) %>% 
    dplyr::bind_rows(.id = "Subject")
drive_map <- c(1:8)
names(drive_map) <- c("BL", "PD", "RD", "ND", "CD", "ED", "MD", "FD")
df$Drive <- names(drive_map[df$Drive])
subject_df <- subject_bio %>% 
  dplyr::inner_join(psych_df, by=c("subject"= "subject")) %>%
  as.data.frame()
df_md <- df %>%  dplyr::filter(Drive == "MD") %>% 
  dplyr::select(
    Subject, Time, Distance, Lane.Position, LaneOffset, Drive, Stimulus, 
    Gaze.X.Pos, Gaze.Y.Pos, Lft.Pupil.Diameter, Rt.Pupil.Diameter) %>%
  dplyr::filter(Subject != "T001") %>% # Drivers without LaneOffset
  dplyr::filter(Subject != "T055") %>%
  dplyr::filter(Subject != "T062") %>%
  dplyr::filter(Subject != "T066") %>%
  dplyr::filter(!is.na(LaneOffset)) %>%
  dplyr::filter(Distance >= 250) %>%         # Remove driver starts
  dplyr::filter(Distance <= 11000) %>%       # Remove driver ends
  dplyr::inner_join(subject_df, by=c("Subject"="subject")) %>% 
  dplyr::mutate(half=ifelse(Distance < 5000, 1, 2)) %>% # ID first half
  dplyr::mutate(Stimulus=as.factor(Stimulus))

feather::write_feather(df_md, here::here("etc", "cleaner_data", "df_select.feather"))
feather::write_feather(subject_df, here::here("etc", "cleaner_data", "subject_df.feather"))

rm(subject_bio, psych_df, subject, df)
rm(file_paths, index_data, drive_map)
```
```{r graph_all}
rect <- data.frame(xmin=5000, xmax=Inf, ymin=-Inf, ymax=Inf)
all_plot <- ggplot(df_md, aes(Distance, Lane.Position)) + 
  geom_line(aes(colour=Subject)) +
    geom_rect(data=rect, aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax),
              color="transparent", alpha=0.25, inherit.aes = FALSE) +
    geom_line(aes(colour=Subject)) + 
    theme_bw() + 
    theme(legend.position = "none") + 
    ggtitle("MD Drive") +
    xlab("Distance (m)") + 
    ylab("Lane Position(m)") +
    coord_cartesian(ylim=c(-5.5, 7)) +
    annotate("text", x=5750, y=0, label="Lane Change",
             angle=90, color="Red",  size=4, hjust=0) +
    annotate("text", x=1750, y=6.25, label="Model Focus",
             size=5, hjust=0, color="blue") 
all_plot
ggsave(filename=here::here('etc', 'plots', '01_all.png'),
       plot = all_plot,
       width=8, height=6)
rm(rect, all_plot)
```
```{r md_half_data}
df_md <- feather::read_feather(here::here('etc', 'cleaner_data', 'df_select.feather'))
df_md_half1 <- df_md %>% 
    dplyr::filter(
        !dplyr::between(Distance, 5000, 7000)) %>% # Remove lane change
  dplyr::mutate(half=ifelse(Distance < 5000, 1, 2)) %>%
  dplyr::mutate(Stimulus=as.factor(Stimulus)) %>%
  dplyr::filter(half==1) %>%
  dplyr::group_by(Subject, Drive) %>%
  dplyr::mutate(ntile=ntile(Distance, 200)) %>% # Bins for resampling
  dplyr::select(-half, -Time, -Lft.Pupil.Diameter, -Rt.Pupil.Diameter) %>% 
  dplyr::arrange(Subject, Drive, Distance) %>% 
  dplyr::group_by(Subject, Drive, ntile) %>%
  dplyr::mutate(mrank=dplyr::row_number()) %>% 
  dplyr::filter(mrank==1) %>%
  dplyr::select(-mrank) %>%  dplyr::ungroup()
saveRDS(df_md_half1, file=here::here('etc', 'cleaner_data', 'md_half_df.RData'))
rm(df_md, df_md_half1)
```

# Univariate
```{r graph_md_acf}
df_md_half1 <- readRDS(file=here::here(
  'etc', 'cleaner_data', 'md_half_df.RData'))
df_md_t021_half1 <- df_md_half1 %>% dplyr::filter(Subject=="T021")

conf.level <- 0.95
acf_md <- acf(df_md_t021_half1$Lane.Position, plot=FALSE)
acf_md_df <- with(acf_md, data.frame(lag, acf))
ciline <- qnorm((1 - conf.level)/2)/sqrt(
  length(df_md_t021_half1$Lane.Position))

md_acf <- ggplot(acf_md_df, aes(lag, acf)) +
    geom_segment(aes(xend=lag, yend=0)) +
    geom_hline(aes(yintercept=0)) + 
    geom_hline(aes(yintercept= -ciline), linetype=2, color='darkblue') +
    geom_hline(aes(yintercept= ciline), linetype=2, color='darkblue') +
    theme_bw() + 
    theme(legend.position = "none") + 
    ggtitle("Texting Driving (T021 Driver)") +
    xlab("Lag") + 
    ylab("ACF")
md_acf
ggsave(filename=here::here('etc', 'plots', '02_acf.png'),
       plot = md_acf,
       width=8, height=6)
saveRDS(df_md_t021_half1,
        file=here::here('etc', 'cleaner_data', 'md_half_t021.RData'))
rm(acf_md, acf_md_df, ciline, md_acf, conf.level)
rm(df_md_half1, df_md_t021_half1)
```
```{r data_plot}
md_half <- readRDS(here('etc', 'cleaner_data', 'md_half_t021.RData'))
ggplot(md_half, aes(Distance, LaneOffset)) +
    geom_line() +
    geom_point(aes(colour=Stimulus), size=1.5) +
    theme_bw() + 
    theme(legend.position = "bottom",
          legend.background = element_rect(
            fill="gray90", size=.5, linetype="dotted")) + 
    ggtitle("Texting Driving (T021 Driver)") +
    xlab("Distance (m)") + 
    ylab("Lane Offset (m)") +
    coord_cartesian(ylim=c(-0.75, .5)) +
    scale_color_manual(labels=c("No Distraction", "Texting"),
                       values=c(colors$c_mid_highlight, colors$d_mid_highlight))
ggsave(filename=here::here('etc', 'plots', '03_t021.png'),
       plot = last_plot(),
       width=8, height=6)
rm(md_half)
```

## 1. Conceptual Analysis
Auto-regressive model 

## 2. Define observations
```{r obs}
writeLines(readLines(here("src", "stan", "ar1_texting.stan"), n=6))
```

## 3. Summary statistics
Correlogram of variances, histogram of variance

## 4. Build generative model
```{r generative_model}
writeLines(readLines(here("src", "stan", "gen_ar1_texting.stan")))
```

```{r model}
writeLines(readLines(here("src", "stan", "ar1_texting.stan")))
```

## 5. Analyze generative ensemble
```{r generate_ensemble, results="hide"}
R <- 1000;
md_half <- readRDS(here('etc', 'cleaner_data', 'md_half_t021.RData'))
input_data <- list("y" = md_half$LaneOffset,
                   "texting" = as.integer(md_half$Stimulus),
                   "N" = length(md_half$Lane.Position),
                   "N_texting" = length(unique(as.integer(md_half$Stimulus))))
simu_data <- list("N" = input_data$N,
                  "texting" = input_data$texting,
                  "N_texting" = input_data$N_texting)
fit <- stan(here("src", "stan", "gen_ar1_texting.stan"), 
            data=simu_data, iter=R, warmup=0, chains=1, refresh=R, seed=234987,
            algorithm="Fixed_param")
saveRDS(fit, here('etc', 'fits', 'ar1_gen.RData'))
simu_alphas         <- extract(fit)$alpha
simu_rhos           <- extract(fit)$rho
simu_sigmas         <- extract(fit)$sigma
simu_delta_textings <- extract(fit)$delta_texting
simu_ys             <- extract(fit)$y_ppc
hash <- sha1(c(readLines(here("src", "stan", "gen_ar1_texting.stan")),
               readLines(here("src", "stan", "ar1_texting.stan")), 
               as.character(R)))
```

```{r prior_predictive}
probs <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
# prior predictive time series
post <- as.matrix(fit)
sel <- grep("y_ppc", colnames(post))
ci50 <- matrix(NA, nrow = length(sel), ncol = 2)
ci90 <- matrix(NA, nrow = length(sel), ncol = 2)
for (i in 1:length(sel)) {
  ci50[i,] <- quantile(post[,sel[i]], prob = c(0.25, 0.75), names = FALSE)
  ci90[i,] <- quantile(post[,sel[i]], prob = c(0.05, 0.95), names = FALSE)
}

png(filename=here('etc', 'plots', '04_ar1_prior_predict.png'),
    width=800, height=600)
plot(0, type= "n", 
     xlim = c(0,max(md_half$Distance)), ylim = c(-10, 10),
     xlab = "Distance", ylab = "Lane Offset (m)",
     main = "Prior Predictive Lane Offset\n50% and 90% intervals")
t <- md_half$Distance
polygon(c(rev(t), t), c(rev(ci90[,1]), ci90[,2]),
        col = colors$c_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[,1]), ci50[,2]),
        col = colors$c_mid, border = FALSE)
t <- md_half$Distance[which(input_data$texting==2)]
i <- which(input_data$texting==2)
polygon(c(rev(t), t), c(rev(ci90[i,1]), ci90[i,2]),
        col = colors$d_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[i,1]), ci50[i,2]),
        col = colors$d_mid, border = FALSE)
legend("bottomright", c("No stimulus", "Texting"),
       col = c(colors$c_mid, colors$d_mid), lwd = c(2,2,2), text.font=0.5)
rm(t, i, ci50, ci90, probs, sel)
dev.off()
rm(fit)
```

```{r test_5_iters, eval=}
r <- 1
simu_alpha         <- simu_alphas[r]
simu_sigma         <- simu_sigmas[r]
simu_rho           <- simu_rhos[r]
simu_delta_texting <- simu_delta_textings[r]
simu_y             <- simu_ys[r, 1:200]
simu_data <- list("y" = simu_y, 
                 "N" = length(simu_y), 
                 "N_texting" = input_data$N_texting, 
                 "texting" = input_data$texting)
fit <- stan(here('src', 'stan', 'ar1_texting.stan'), data=simu_data)
summary(fit, pars=c("alpha", "sigma", "rho", "delta_texting"), prob=c())$summary
plot(fit, pars=c("alpha", "sigma", "rho", "delta_texting"))
simu_df_params = data.frame(alpha = simu_alphas[r], 
                            sigma = simu_sigmas[r],
                            rho = simu_rhos[r],
                            delta = simu_delta_textings[r])
simu_df_params
util <- new.env()
source(here('src', 'codebase', 'stan_utility.R'), local=util)

warning_code <- util$check_all_diagnostics(fit, quiet=TRUE)

# Compute rank of prior draw with respect to thinned posterior draws
sbc_rank_alpha <- sum(simu_alpha < extract(fit)$alpha[seq(1, 4000 - 8, 8)])
sbc_rank_sigma <- sum(simu_sigma < extract(fit)$sigma[seq(1, 4000 - 8, 8)])
sbc_rank_rho <- sum(simu_rho < extract(fit)$rho[seq(1, 4000 - 8, 8)])
sbc_rank_delta_texting <- sum(simu_delta_texting < extract(fit)$delta_texting[seq(1, 4000 - 8, 8)])

# Compute posterior sensitivities
s <- summary(fit, probs = c(), pars='alpha')$summary
post_mean_alpha <- s[,1]
post_sd_alpha <- s[,3]
prior_sd_alpha <- 1
z_score_alpha <- abs((post_mean_alpha - simu_alpha) / post_sd_alpha)
shrinkage_alpha <- 1 - (post_sd_alpha / prior_sd_alpha)**2

s <- summary(fit, probs = c(), pars='sigma')$summary
post_mean_sigma <- s[,1]
post_sd_sigma <- s[,3]
prior_sd_sigma <- sqrt(1^2 * (1 - 2 / pi))
z_score_sigma <- abs((post_mean_sigma- simu_sigma) / post_sd_sigma)
shrinkage_sigma <- 1 - (post_sd_sigma / prior_sd_sigma)**2

s <- summary(fit, probs = c(), pars='rho')$summary
post_mean_rho <- s[,1]
post_sd_rho <- s[,3]
prior_sd_rho <- sqrt(1/12 * (1 - 0)^2)
z_score_rho <- abs((post_mean_rho - simu_rho) / post_sd_rho)
shrinkage_rho <- 1 - (post_sd_rho / prior_sd_rho)**2

s <- summary(fit, probs = c(), pars='delta_texting')$summary
post_mean_delta_texting <- s[,1]
post_sd_delta_texting <- s[,3]
prior_sd_delta_texting <- sqrt(1^2 * (1 - 2 / pi))
z_score_delta_texting <- abs((post_mean_delta_texting - simu_delta_texting) /
                             post_sd_delta_texting)
shrinkage_delta_texting <- 1 - (post_sd_delta_texting/ prior_sd_delta_texting)**2

output <- c(warning_code,
  sbc_rank_alpha, z_score_alpha, shrinkage_alpha,
  sbc_rank_rho, z_score_rho, shrinkage_rho,
  sbc_rank_sigma, z_score_sigma, shrinkage_sigma,
  sbc_rank_delta_texting, z_score_delta_texting, shrinkage_delta_texting)
print(c("warning_code", 
        "sbc_rank_alpha",  "z_score_alpha",  "shrinkage_alpha",
        "sbc_rank_rho", "z_score_rho", "shrinkage_rho",
        "sbc_rank_sigma", "z_score_sigma", "shrinkage_sigma",
        "sbc_rank_delta_texting", "z_score_delta_texting", "shrinkage_delta_texting"))
print(output)
rm(fit)
```

```{r create_zips, echo=FALSE, results="hide"}
simu_list <- t(data.matrix(data.frame(simu_alphas, simu_sigmas, simu_rhos, simu_delta_textings, simu_ys)))
stan_file <- 'ar1_texting.stan'
fit_model <- stan_model(here('src', 'stan', stan_file))
dir.create(paste("/tmp/zip_files/", hash, "/", sep=""), recursive=TRUE)

create_zip <- function(r, hash, simu_list, stan_file) {
  library(here)
  simu <- simu_list[, r]
  simu_alpha         <- simu[1]
  simu_sigma         <- simu[2]
  simu_rho           <- simu[3]
  simu_delta_texting <- simu[4]
  simu_y             <- simu[5:length(simu_list[, 1])]
  
  stan_name <- strsplit(stan_file, "[.]")[[1]][1]
  tmp_dir <- paste("/tmp/", hash, "_", as.character(r), sep="")
  zip_file_path <- paste("/tmp/zip_files/", hash, "/", 
                         hash, "_", as.character(r), ".zip", sep="")
  simu_data_path <- paste(tmp_dir, "/simu_data.Rdata", sep="")
  myjob_path <- here("src", "docker", "myjob.sh")
  rds_path <- here("src", "stan",  paste(
    strsplit(stan_file, "[.]")[[1]][1], ".rds", sep=""))
  stan_path <- here("src", "stan", stan_file)
  r_script_path <- here("src", "docker", 
                        stan_name, paste(
                          strsplit(stan_file, "[.]")[[1]][1], ".R", sep=""))
  s3_key <- paste("stan_runs/", stan_file, "/", hash, "_", as.character(r), ".zip", sep="")
  
  dir.create(tmp_dir)
  simu_data <- list("y" = simu_y, 
                   "N" = length(simu_y), 
                   "N_texting" = input_data$N_texting, 
                   "texting" = input_data$texting)
  file.copy(from=here('src', 'codebase', 'stan_utility.R'), to=tmp_dir)
  file.copy(from=stan_path, to=tmp_dir)
  file.copy(from=rds_path, to=tmp_dir)
  file.copy(from=myjob_path, to=tmp_dir)
  file.copy(from=r_script_path, to=tmp_dir)
  save(simu_data, simu_alpha, simu_sigma, simu_rho, simu_delta_texting, file=simu_data_path)  
  files2zip <- dir(tmp_dir, full.names = TRUE)
  zip(zipfile = zip_file_path, files = files2zip)
  aws.s3::put_object(zip_file_path, object=s3_key, bucket="stat685-batch") 
}
```

```{r send_to_aws, results="hide"}
# Run single iteration
1 %>% map(function(x) create_zip(x, hash, simu_list, "ar1_texting.stan"))

# Run all iterations
library(foreach)
library(doParallel)
registerDoParallel(makeCluster(detectCores()))
foreach(i=2:R) %dopar% create_zip(i, hash, simu_list, stan_file)
```

```{r cleanup_prep_results}
system(paste("rm -rf ", "/tmp/", hash, "*", sep=""))
system(paste("rm -rf ", "/tmp/zip_files/", hash, "/", sep=""))
sys_output <- system(paste("aws s3 ls s3://stat685-batch/results/", stan_file, "/", hash, "/", sep=""), intern=TRUE)
if (length(sys_output) < 2) {
  print("didn't run")
}
```

```{r results}
result_dir <- here("etc", "results", stan_file)
dir.create(result_dir)
system(paste("aws s3 cp s3://stat685-batch/results/", stan_file, "/ ", result_dir, "/ --recursive", sep=""))
```

**Fit the simulated observations and evaluate
```{r}
library(foreach)
library(doParallel)
result_dir <- here("etc", "results", stan_file)
stan_file <- 'ar1_texting.stan'
registerDoParallel(makeCluster(detectCores()))
output_list <- dir(paste(result_dir, "/", hash, sep=""))
ensemble_output <- foreach(output=output_list, .combine='cbind') %dopar% {
   readRDS(paste(result_dir, "/", hash, "/", output, sep=""))
}
```

```{r warning_codes}
warning_code <- ensemble_output[1,]
if (sum(warning_code) != 0) {
  percentage <- length(warning_code[warning_code!=0]) / length(output_list) * 100
  print ("Some simulated posterior fits in the generative ensemble encountered problems!")
  print ("Percentage with problems:")
  print (percentage)
} else {
  print ("No posterior fits in the generative ensemble encountered problems!")
}
rm(percentage, warning_code)
```

```{r sbc}
png(filename=here(
  "etc", "plots", "ar1_texting_sbc_shrink.png"), 
  width=800, height=600)

par(mfrow=c(2, 4))
sbc_rank <- ensemble_output[2,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (alpha)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)

sbc_rank <- ensemble_output[5,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (sigma)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)

sbc_rank <- ensemble_output[8,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (rho)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)

sbc_rank <- ensemble_output[11,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (delta)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)

# alpha
z_score <- ensemble_output[3,]
shrinkage <- ensemble_output[4,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, 
     main="alpha", xlim=c(0, 1), xlab="Posterior Shrinkage",
     ylim=c(0, 5), ylab="Posterior z-Score")

# rho
z_score <- ensemble_output[6,]
shrinkage <- ensemble_output[7,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, 
     main="sigma", xlim=c(0, 1), xlab="Posterior Shrinkage",
     ylim=c(0, 5), ylab="Posterior z-Score")

# sigma
z_score <- ensemble_output[9,]
shrinkage <- ensemble_output[10,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, 
     main="rho", xlim=c(0, 1), xlab="Posterior Shrinkage", 
     ylim=c(0, 5), ylab="Posterior z-Score")

# delta_texting
z_score <- ensemble_output[12,]
shrinkage <- ensemble_output[13,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, 
     main="Delta", xlim=c(0, 1), xlab="Posterior Shrinkage",
     ylim=c(0, 5), ylab="Posterior z-Score")

par(mfrow = c(1, 1))
dev.off()
rm(bar_x, bar_y, high, low, mid)
rm(output_list, R, result_dir, ensemble_output)
rm(sbc_rank, shrinkage, sbc_hist, post,
   simu_alphas, simu_delta_textings, simu_rhos, simu_sigmas, z_score, simu_data,
   simu_ys, post)
```

## 6. Fit observations and evaluate
```{r actual_fit}
fit <- stan(file=here('src', 'stan', 'ar1_texting.stan'),
            data=input_data, seed=4938483, refresh=2000)
saveRDS(fit, file=here('etc', 'fits', 'ar1_texting_stan_fit.RData'))
```

```{r ar1_fit}
fit <- readRDS(here('etc', 'fits', 'ar1_texting_stan_fit.RData'))
posterior <- extract(fit, inc_warmup = TRUE, permuted = FALSE)
p <- mcmc_trace(posterior, pars = c("alpha", "sigma", "rho", "delta_texting"),
                n_warmup=200)
plot(fit, pars=c("alpha", "sigma", "rho", "delta_texting"))
rm(posterior, p)
```

## 7. Posterior Predictive Check
```{r}
y <- input_data$y
my_sso <- shinystan::launch_shinystan(fit)
```

```{r ppc_time_series}
md_half <- readRDS(here('etc', 'cleaner_data', 'md_half_t021.RData'))
fit <- readRDS(here('etc', 'fits', 'ar1_texting_stan_fit.RData'))
input_data <- list("y" = md_half$LaneOffset,
                   "texting" = as.integer(md_half$Stimulus),
                   "N" = length(md_half$Lane.Position),
                   "N_texting" = length(unique(as.integer(md_half$Stimulus))))
post <- as.matrix(fit)
sel <- grep("y_ppc", colnames(post))
# compute the credible intervals
ci50 <- matrix(NA, nrow = length(sel), ncol = 2)
ci95 <- matrix(NA, nrow = length(sel), ncol = 2)
for (i in 1:length(sel)) {
  ci50[i,] <- quantile(post[,sel[i]], prob = c(0.25, 0.75), names = FALSE)
  ci95[i,] <- quantile(post[,sel[i]], prob = c(0.025, 0.975), names = FALSE)
}

plot(0, type= "n", 
     xlim = c(0, max(md_half$Distance)), ylim = range(post[, sel]),
     xlab = "Distance", ylab = "Lane Offset",
     main = "AR(1) Model - Texting driving")
t <- md_half$Distance
polygon(c(rev(t), t), c(rev(ci95[,1]), ci95[,2]),
        col = colors$c_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[,1]), ci50[,2]),
        col = colors$c_mid, border = FALSE)
t <- md_half$Distance[which(input_data$texting==2)]
i <- which(input_data$texting==2)
polygon(c(rev(t), t), c(rev(ci95[i,1]), ci95[i,2]),
        col = colors$d_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[i,1]), ci50[i,2]),
        col = colors$d_mid, border = FALSE)
lines(md_half$Distance, colMeans(post[,sel]), col = "hotpink", lwd = 3)

# plot true series
lines(md_half$Distance, input_data$y, col = "#0c120c", lwd = 2)
legend("bottomright", c("actual", "pred (avg)", "Normal", "Texting"),
       col = c("#0c120c", "hotpink", colors$c_mid, colors$d_mid),
       lwd = c(2,2,2), text.font=0.5)
rm(i, t, sel, ci50, ci95)
rm(fit, post)
```

```{r ppc_correlogram}
B <- 23
obs_acf <- acf(input_data$y, plot=FALSE)$acf

idx <- rep(1:B, each=2)
x <- sapply(1:length(idx),
            function(b) if(b %% 2 == 0) idx[b] + 0.5 else idx[b] - 0.5)
pad_obs <- do.call(cbind, lapply(idx, function(n) obs_acf[n]))
params <- extract(fit)
counts <- sapply(1:4000, function(n) acf(params$y_ppc[n,], plot=FALSE)$acf)
probs <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:B, function(b) quantile(counts[b, ], probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

plot(1, type="n", main="Posterior Predictive Correlogram",
     xlim=c(0.5, B + 0.5), xlab="Lag", ylim=c(0, max(cred[9,])), ylab="")
polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = colors$c_light, border = NA)
polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = colors$c_light_highlight, border = NA)
polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = colors$c_mid, border = NA)
polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = colors$c_mid_highlight, border = NA)
lines(x, pad_cred[5,], col=colors$c_dark, lwd=2) 
lines(x, pad_obs, col="white", lty=1, lw=2.5)
lines(x, pad_obs, col="black", lty=1, lw=2)
rm(B, idx, x, pad_obs, params, counts, probs, cred, pad_cred, obs_acf)
```

# Multivariate drivers
## 2. Define observations
```{r}
writeLines(readLines(here('src', 'stan', 'ar1_texting_multi.stan'), n=8))
```

## 3. Summary statistics
```{r prelim_analysis}
md_half_all <- readRDS(here('etc', 'cleaner_data', 'md_half_df.RData'))
subject_df <- md_half_all %>% 
  group_by(Subject, gender, age_group, tai, type_ab) %>% 
  summarize(sd = sd(LaneOffset)) %>%
  select(Subject, gender, age_group, tai, type_ab)
input_data <- list("N_drivers" = length(unique(md_half_all$Subject)),
                   "N_age" = length(unique(md_half_all$age_group)),
                   "N_time" = 200,
                   "N" = 200 * length(unique(md_half_all$Subject)),
                   "N_texting" = 2,
                   "texting" = as.integer(md_half_all$Stimulus),
                   "age" = as.integer(as.factor(subject_df$age_group)),
                   "y" = md_half_all$LaneOffset)
agg_data <- md_half_all %>% group_by(Subject) %>% 
  summarize(sd = sd(LaneOffset)) %>%
  left_join(subject_df, by="Subject")

agg_data_stim <- md_half_all %>% group_by(Subject, Stimulus) %>% 
  summarize(sd = sd(LaneOffset)) %>%
  left_join(subject_df, by="Subject")

levels(agg_data_stim$Stimulus) <- c("Normal", "Texting")
p1 <- ggplot(agg_data, aes(type_ab, sd)) + geom_point() +
  xlab("Type AB")
p2 <- ggplot(agg_data, aes(tai, sd)) + geom_point() +
  xlab("Anxiety")
p3 <- ggplot(agg_data_stim, aes(gender, sd)) + geom_violin() +
  facet_grid(. ~ Stimulus)
p4 <- ggplot(agg_data_stim, aes(age_group, sd)) + geom_violin() +
  facet_grid(. ~ Stimulus)
grid.arrange(p1, p2, p3, p4, nrow = 2)
rm(p1, p2, p3, p4)
rm(agg_data, agg_data_stim)
```

## 6. Fit observations
```{r multi_fit}
fit_multi <- stan(here('src', 'stan', 'ar1_texting_multi.stan'), 
                  data=input_data)
saveRDS(fit_multi, file=here('etc', 'fits', 'ar1_texting_multi.RData'))
```

```{r multi_eval, eval=FALSE}
fit_multi <- readRDS(file=here('etc', 'fits', 'ar1_texting_multi.RData'))
plot(fit_multi, pars=c("sigma_base", "delta_texting"))
posterior_multi <- as.matrix(fit_multi)
plot_title <- ggtitle("Posterior distributions",
                      "with medians and 80% intervals")
mcmc_areas(posterior_multi, 
           pars = c("sigma_base", "delta_texting"), 
           prob = 0.8) + plot_title
rm(fit_multi, posterior_multi, plot_title)
```

# Multivariate drivers - pooled
## 6. Fit observations
```{r, results="hide"}
fit_pooled <- stan(here('src', 'stan', 'ar1_texting_multi_pooled.stan'),
                   data=input_data)
saveRDS(fit_pooled,
        file=here('etc', 'fits', 'ar1_texting_multi_pooled.RData'))
```

```{r}
fit_pooled <- readRDS(
  file=here('etc', 'fits', 'ar1_texting_multi_pooled.RData')) 
posterior_pooled <- as.matrix(fit_pooled)
plot_title <- ggtitle("Posterior distributions",
                      "with medians and 80% intervals")
mcmc_areas(posterior_pooled, 
           pars = c("sigma_base", "delta_base"), 
           prob = 0.8) + plot_title
rm(plot_title)
```

## Age groups
```{r, message=FALSE}
fit_pooled <- readRDS(
  file=here('etc', 'fits', 'ar1_texting_multi_pooled.RData')) 
posterior_pooled <- as.matrix(fit_pooled)
drivers_old <- which(subject_df$age_group == "Old")
drivers_new <- which(subject_df$age_group == "Young")

par_interest <- "delta_texting_driver"
par_names <- sprintf("%s[%d]", par_interest, drivers_old)
dimnames(posterior_pooled)$parameters[
  dimnames(posterior_pooled)$parameters %in% par_names] <- subject_df$Subject[subject_df$age_group == "Old"] 
p1 <- mcmc_intervals(posterior_pooled,
               pars=subject_df$Subject[subject_df$age_group == "Old"]) +
  ggtitle("Old drivers: Texting effect") + xlim(-0.1, 0.9)

par_names <- sprintf("%s[%d]", par_interest, drivers_new)
par_select <- dimnames(fit_multi)$parameters[dimnames(fit_multi)$parameters %in% par_names]
dimnames(posterior_pooled)$parameters[
  dimnames(posterior_pooled)$parameters %in% par_names] <- subject_df$Subject[subject_df$age_group == "Young"] 
p2 <- mcmc_intervals(posterior_pooled,
               pars=subject_df$Subject[subject_df$age_group == "Young"]) +
  ggtitle("Young drivers: Texting effect") + xlim(-0.1, 0.9)
grid.arrange(p2, p1, nrow=1)
rm(p1, p2, drivers_old, drivers_new, par_names, par_select, par_interest, 
   posterior_pooled)
```

# Mulivariate with age groups
```{r}
md_half_all <- readRDS(here('etc', 'cleaner_data', 'md_half_df.RData'))
subject_df <- md_half_all %>% 
  group_by(Subject, gender, age_group, tai, type_ab) %>% 
  summarize(sd = sd(LaneOffset)) %>%
  select(Subject, gender, age_group, tai, type_ab)
input_data <- list("N_drivers" = length(unique(md_half_all$Subject)),
                   "N_age" = length(unique(md_half_all$age_group)),
                   "N_time" = 200,
                   "N" = 200 * length(unique(md_half_all$Subject)),
                   "N_texting" = 2,
                   "texting" = as.integer(md_half_all$Stimulus),
                   "age" = as.integer(as.factor(subject_df$age_group)),
                   "y" = md_half_all$LaneOffset)
fit_age <- stan(here('src', 'stan', 'ar1_texting_age.stan'), 
                  data=input_data, control = list(max_treedepth = 15))
saveRDS(fit_age, file=here('etc', 'fits', 'ar1_texting_age.RData'))
posterior_age <- as.matrix(fit_age)
mcmc_areas(posterior_age, regex_pars = c("^sigma_texting"), prob=0.8)
```