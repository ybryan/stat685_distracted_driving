---
title: "Univariate AR model with texting"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cahce = TRUE)

library(here)
library(rstan)
library(dplyr)
library(ggplot2)
library(digest)
library(purrr)
library(aws.s3)
library(aws.ec2metadata)
library(aws.signature)

util <- new.env()
source(here('src', 'codebase', 'stan_utility.R'), local=util)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

load(here('md_lane.RData'))
input_data <- list("y" = md_half$LaneOffset,
                   "texting" = as.integer(md_half$Stimulus),
                   "N" = length(md_half$Lane.Position),
                   "N_texting" = length(unique(as.integer(md_half$Stimulus))))
colors <- list(c_light=c("#DCBCBC"), c_light_highlight=c("#C79999"),
               c_mid=c("#B97C7C"),   c_mid_highlight=c("#A25050"),
               c_dark=c("#8F2727"),  c_dark_highlight=c("#7C0000"),
               d_light=c("#BCBCDC"), d_light_highlight=c("#9999C7"),
               d_mid=c("#7C7CB9"),   d_mid_highlight=c("#5050A2"),
               d_dark=c("#27278F"),  d_dark_highlight=c("#00007c"))
```

```{r data_plot}
ggplot(md_half, aes(Distance, LaneOffset)) +
    geom_line() +
    geom_point(aes(colour=Stimulus), size=1.5) +
    theme_bw() + 
    theme(legend.position = "bottom",
          legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
    ggtitle("Texting Driving") +
    xlab("Distance (m)") + 
    ylab("Lane Offset (m)") +
    coord_cartesian(ylim=c(-0.75, .5)) +
    scale_color_manual(labels=c("No Distraction", "Texting"),
                       values=c(colors$c_mid_highlight, colors$d_mid_highlight))
```

# 1. Conceptual Analysis
Auto-regressive model 

# 2. Define observations
```{r obs}
writeLines(readLines(here("src", "stan", "ar1_texting.stan"), n=6))
```

# 3. Summary statistics
Correlogram of variances, histogram of variance

# 4. Build generative model
```{r generative_model}
writeLines(readLines(here("src", "stan", "gen_ar1_texting.stan")))
```

```{r model}
writeLines(readLines(here("src", "stan", "ar1_texting.stan")))
```

# 5. Analyze generative ensemble

```{r generate_ensemble, results="hide"}
R <- 1000;
simu_data <- list("N" = input_data$N,
                  "texting" = input_data$texting,
                  "N_texting" = input_data$N_texting)
fit <- stan(here("src", "stan", "gen_ar1_texting.stan"), 
            data=simu_data, iter=R, warmup=0, chains=1, refresh=R, seed=234987,
            algorithm="Fixed_param")
simu_alphas         <- extract(fit)$alpha
simu_rhos           <- extract(fit)$rho
simu_sigmas         <- extract(fit)$sigma
simu_delta_textings <- extract(fit)$delta_texting
simu_ys             <- extract(fit)$y_ppc
hash <- sha1(c(readLines(here("src", "stan", "gen_ar1_texting.stan")),
               readLines(here("src", "stan", "ar1_texting.stan")), 
               as.character(R)))
```

```{r prior_predictive}
probs <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
# prior predictive time series
post <- as.matrix(fit)
sel <- grep("y_ppc", colnames(post))
ci50 <- matrix(NA, nrow = length(sel), ncol = 2)
ci95 <- matrix(NA, nrow = length(sel), ncol = 2)
for (i in 1:length(sel)) {
  ci50[i,] <- quantile(post[,sel[i]], prob = c(0.25, 0.75), names = FALSE)
  ci95[i,] <- quantile(post[,sel[i]], prob = c(0.025, 0.975), names = FALSE)
}

plot(0, type= "n", 
     xlim = c(0,max(md_half$Distance)), ylim = c(-1, 1),
     xlab = "Distance", ylab = "Lane Offset (m)",
     main = "Prior Predictive Lane Offset\n50% and 90% intervals")
t <- md_half$Distance
polygon(c(rev(t), t), c(rev(ci95[,1]), ci95[,2]), col = colors$c_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[,1]), ci50[,2]), col = colors$c_mid, border = FALSE)
t <- md_half$Distance[which(input_data$texting==2)]
i <- which(input_data$texting==2)
polygon(c(rev(t), t), c(rev(ci95[i,1]), ci95[i,2]), col = colors$d_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[i,1]), ci50[i,2]), col = colors$d_mid, border = FALSE)
legend("bottomright", c("No stimulus", "Texting"), col = c(colors$c_mid, colors$d_mid), lwd = c(2,2,2), text.font=0.5)
```

```{r test_5_iters}
r <- 1
simu_alpha         <- simu_alphas[r]
simu_sigma         <- simu_sigmas[r]
simu_rho           <- simu_rhos[r]
simu_delta_texting <- simu_delta_textings[r]
simu_y             <- simu_ys[r, 1:200]
simu_data <- list("y" = simu_y, 
                 "N" = length(simu_y), 
                 "N_texting" = input_data$N_texting, 
                 "texting" = input_data$texting)
fit <- stan(here('src', 'stan', 'ar1_texting.stan'), data=simu_data)
summary(fit, pars=c("alpha", "sigma", "rho", "delta_texting"), prob=c())$summary
plot(fit, pars=c("alpha", "sigma", "rho", "delta_texting"))
simu_df_params = data.frame(alpha = simu_alphas[r], 
                            sigma = simu_sigmas[r],
                            rho = simu_rhos[r],
                            delta = simu_delta_textings[r])
simu_df_params
util <- new.env()
source(here('src', 'codebase', 'stan_utility.R'), local=util)

warning_code <- util$check_all_diagnostics(fit, quiet=TRUE)

# Compute rank of prior draw with respect to thinned posterior draws
sbc_rank_alpha <- sum(simu_alpha < extract(fit)$alpha[seq(1, 4000 - 8, 8)])
sbc_rank_sigma <- sum(simu_sigma < extract(fit)$sigma[seq(1, 4000 - 8, 8)])
sbc_rank_rho <- sum(simu_rho < extract(fit)$rho[seq(1, 4000 - 8, 8)])
sbc_rank_delta_texting <- sum(simu_delta_texting < extract(fit)$delta_texting[seq(1, 4000 - 8, 8)])

# Compute posterior sensitivities
s <- summary(fit, probs = c(), pars='alpha')$summary
post_mean_alpha <- s[,1]
post_sd_alpha <- s[,3]
prior_sd_alpha <- 1
z_score_alpha <- abs((post_mean_alpha - simu_alpha) / post_sd_alpha)
shrinkage_alpha <- 1 - (post_sd_alpha / prior_sd_alpha)**2

s <- summary(fit, probs = c(), pars='sigma')$summary
post_mean_sigma <- s[,1]
post_sd_sigma <- s[,3]
prior_sd_sigma <- sqrt(1^2 * (1 - 2 / pi))
z_score_sigma <- abs((post_mean_sigma- simu_sigma) / post_sd_sigma)
shrinkage_sigma <- 1 - (post_sd_sigma / prior_sd_sigma)**2

s <- summary(fit, probs = c(), pars='rho')$summary
post_mean_rho <- s[,1]
post_sd_rho <- s[,3]
prior_sd_rho <- sqrt(1/12 * (1 - 0)^2)
z_score_rho <- abs((post_mean_rho - simu_rho) / post_sd_rho)
shrinkage_rho <- 1 - (post_sd_rho / prior_sd_rho)**2

s <- summary(fit, probs = c(), pars='delta_texting')$summary
post_mean_delta_texting <- s[,1]
post_sd_delta_texting <- s[,3]
prior_sd_delta_texting <- sqrt(1^2 * (1 - 2 / pi))
z_score_delta_texting <- abs((post_mean_delta_texting - simu_delta_texting) /
                             post_sd_delta_texting)
shrinkage_delta_texting <- 1 - (post_sd_delta_texting/ prior_sd_delta_texting)**2

output <- c(warning_code,
  sbc_rank_alpha, z_score_alpha, shrinkage_alpha,
  sbc_rank_rho, z_score_rho, shrinkage_rho,
  sbc_rank_sigma, z_score_sigma, shrinkage_sigma,
  sbc_rank_delta_texting, z_score_delta_texting, shrinkage_delta_texting)
print(c("warning_code", 
        "sbc_rank_alpha",  "z_score_alpha",  "shrinkage_alpha",
        "sbc_rank_rho", "z_score_rho", "shrinkage_rho",
        "sbc_rank_sigma", "z_score_sigma", "shrinkage_sigma",
        "sbc_rank_delta_texting", "z_score_delta_texting", "shrinkage_delta_texting"))
print(output)
```

```{r create_zips, echo=FALSE, results="hide"}
simu_list <- t(data.matrix(data.frame(simu_alphas, simu_sigmas, simu_rhos, simu_delta_textings, simu_ys)))
stan_file <- 'ar1_texting.stan'
fit_model <- stan_model(here('src', 'stan', stan_file))
dir.create(paste("/tmp/zip_files/", hash, "/", sep=""), recursive=TRUE)

create_zip <- function(r, hash, simu_list, stan_file) {
  library(here)
  simu <- simu_list[, r]
  simu_alpha         <- simu[1]
  simu_sigma         <- simu[2]
  simu_rho           <- simu[3]
  simu_delta_texting <- simu[4]
  simu_y             <- simu[5:length(simu_list[, 1])]
  
  stan_name <- strsplit(stan_file, "[.]")[[1]][1]
  tmp_dir <- paste("/tmp/", hash, "_", as.character(r), sep="")
  zip_file_path <- paste("/tmp/zip_files/", hash, "/", 
                         hash, "_", as.character(r), ".zip", sep="")
  simu_data_path <- paste(tmp_dir, "/simu_data.Rdata", sep="")
  myjob_path <- here("src", "docker", "myjob.sh")
  rds_path <- here("src", "stan",  paste(
    strsplit(stan_file, "[.]")[[1]][1], ".rds", sep=""))
  stan_path <- here("src", "stan", stan_file)
  r_script_path <- here("src", "docker", 
                        stan_name, paste(
                          strsplit(stan_file, "[.]")[[1]][1], ".R", sep=""))
  s3_key <- paste("stan_runs/", stan_file, "/", hash, "_", as.character(r), ".zip", sep="")
  
  dir.create(tmp_dir)
  simu_data <- list("y" = simu_y, 
                   "N" = length(simu_y), 
                   "N_texting" = input_data$N_texting, 
                   "texting" = input_data$texting)
  file.copy(from=here('src', 'codebase', 'stan_utility.R'), to=tmp_dir)
  file.copy(from=stan_path, to=tmp_dir)
  file.copy(from=rds_path, to=tmp_dir)
  file.copy(from=myjob_path, to=tmp_dir)
  file.copy(from=r_script_path, to=tmp_dir)
  save(simu_data, simu_alpha, simu_sigma, simu_rho, simu_delta_texting, file=simu_data_path)  
  files2zip <- dir(tmp_dir, full.names = TRUE)
  zip(zipfile = zip_file_path, files = files2zip)
  aws.s3::put_object(zip_file_path, object=s3_key, bucket="stat685-batch") 
}
```

```{r send_to_aws, results="hide"}
# Run single iteration
1 %>% map(function(x) create_zip(x, hash, simu_list, "ar1_texting.stan"))

# Run all iterations
library(foreach)
library(doParallel)
registerDoParallel(makeCluster(detectCores()))
foreach(i=2:R) %dopar% create_zip(i, hash, simu_list, stan_file)
```

```{r cleanup_prep_results}
system(paste("rm -rf ", "/tmp/", hash, "*", sep=""))
system(paste("rm -rf ", "/tmp/zip_files/", hash, "/", sep=""))
sys_output <- system(paste("aws s3 ls s3://stat685-batch/results/", stan_file, "/", hash, "/", sep=""), intern=TRUE)
if (length(sys_output) < 2) {
  print("didn't run")
}
```

```{r results}
result_dir <- here("etc", "results", stan_file)
dir.create(result_dir)
system(paste("aws s3 cp s3://stat685-batch/results/", stan_file, "/ ", result_dir, "/ --recursive", sep=""))
```

**Fit the simulated observations and evaluate
```{r}
library(foreach)
library(doParallel)
registerDoParallel(makeCluster(detectCores()))
output_list <- dir(paste(result_dir, "/", hash, sep=""))
ensemble_output <- foreach(output=output_list, .combine='cbind') %dopar% {
   readRDS(paste(result_dir, "/", hash, "/", output, sep=""))
}
```

```{r warning_codes}
warning_code <- ensemble_output[1,]
if (sum(warning_code) != 0) {
  percentage <- length(warning_code[warning_code!=0]) / length(output_list) * 100
  print ("Some simulated posterior fits in the generative ensemble encountered problems!")
  print ("Percentage with problems:")
  print (percentage)
} else {
  print ("No posterior fits in the generative ensemble encountered problems!")
}
```

```{r sbc}
png(filename=here("src", "presentation", "graphics", "prior", "ar1_texting_sbc_shrink.png"), width=800, height=600)
par(mfrow=c(2, 4))
sbc_rank <- ensemble_output[2,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (alpha)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)

sbc_rank <- ensemble_output[5,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (sigma)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)

sbc_rank <- ensemble_output[8,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (rho)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)

sbc_rank <- ensemble_output[11,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (delta)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)

# alpha
z_score <- ensemble_output[3,]
shrinkage <- ensemble_output[4,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, main="alpha",
     xlim=c(0, 1), xlab="Posterior Shrinkage", ylim=c(0, 5), ylab="Posterior z-Score")
# rho
z_score <- ensemble_output[6,]
shrinkage <- ensemble_output[7,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, main="sigma",
     xlim=c(0, 1), xlab="Posterior Shrinkage", ylim=c(0, 5), ylab="Posterior z-Score")
# sigma
z_score <- ensemble_output[9,]
shrinkage <- ensemble_output[10,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, main="rho",
     xlim=c(0, 1), xlab="Posterior Shrinkage", ylim=c(0, 5), ylab="Posterior z-Score")
# delta_texting
z_score <- ensemble_output[12,]
shrinkage <- ensemble_output[13,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, main="Delta",
     xlim=c(0, 1), xlab="Posterior Shrinkage", ylim=c(0, 5), ylab="Posterior z-Score")
par(mfrow = c(1, 1))
dev.off()
```

# 6. Fit observations and evaluate
```{r actual_fit}
fit <- stan(file=here('src', 'stan', 'ar1_texting.stan'), data=input_data, seed=4938483, refresh=2000)
saveRDS(fit, file=here('etc', 'fits', 'ar1_texting_stan_fit.RData'))
pairs(fit, pars=c("alpha", "sigma", "rho", "delta_texting"))
plot(fit, pars=c("alpha", "sigma", "rho", "delta_texting"))
```

# 7. Posterior Predictive Check

```{r}
y <- input_data$y
library(shinystan)
my_sso <- shinystan::launch_shinystan(fit)
```

```{r ppc_time_series}
post <- as.matrix(fit)
sel <- grep("y_ppc", colnames(post))
# compute the credible intervals
ci50 <- matrix(NA, nrow = length(sel), ncol = 2)
ci95 <- matrix(NA, nrow = length(sel), ncol = 2)
for (i in 1:length(sel)) {
  ci50[i,] <- quantile(post[,sel[i]], prob = c(0.25, 0.75), names = FALSE)
  ci95[i,] <- quantile(post[,sel[i]], prob = c(0.025, 0.975), names = FALSE)
}

plot(0, type= "n", 
     xlim = c(0, max(md_half$Distance)), ylim = range(post[, sel]),
     xlab = "Distance", ylab = "Lane Offset", main = "AR(1) Model - Texting driving")
t <- md_half$Distance
polygon(c(rev(t), t), c(rev(ci95[,1]), ci95[,2]), col = colors$c_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[,1]), ci50[,2]), col = colors$c_mid, border = FALSE)
t <- md_half$Distance[which(input_data$texting==2)]
i <- which(input_data$texting==2)
polygon(c(rev(t), t), c(rev(ci95[i,1]), ci95[i,2]), col = colors$d_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[i,1]), ci50[i,2]), col = colors$d_mid, border = FALSE)
lines(md_half$Distance, colMeans(post[,sel]), col = "hotpink", lwd = 3)
# plot true series
lines(md_half$Distance, input_data$y, col = "#0c120c", lwd = 2)
legend("bottomright", c("actual", "pred (avg)", "Normal", "Texting"),
       col = c("#0c120c", "hotpink", colors$c_mid, colors$d_mid),
       lwd = c(2,2,2), text.font=0.5)
```

```{r 1.1.7a}
B <- 23
obs_acf <- acf(input_data$y, plot=FALSE)$acf

idx <- rep(1:B, each=2)
x <- sapply(1:length(idx), function(b) if(b %% 2 == 0) idx[b] + 0.5 else idx[b] - 0.5)
pad_obs <- do.call(cbind, lapply(idx, function(n) obs_acf[n]))
params <- extract(fit)
counts <- sapply(1:4000, function(n) acf(params$y_ppc[n,], plot=FALSE)$acf)
probs <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
cred <- sapply(1:B, function(b) quantile(counts[b, ], probs=probs))
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

plot(1, type="n", main="Posterior Predictive Correlogram",
     xlim=c(0.5, B + 0.5), xlab="Lag", ylim=c(0, max(cred[9,])), ylab="")
 
polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])),
        col = colors$c_light, border = NA)
polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])),
        col = colors$c_light_highlight, border = NA)
polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])),
        col = colors$c_mid, border = NA)
polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])),
        col = colors$c_mid_highlight, border = NA)
lines(x, pad_cred[5,], col=colors$c_dark, lwd=2)

lines(x, pad_obs, col="white", lty=1, lw=2.5)
lines(x, pad_obs, col="black", lty=1, lw=2)
```

