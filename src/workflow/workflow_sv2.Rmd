---
title: "Univariate Stochastic Volatility Model with Texting and Not Texting"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cahce = TRUE)

library(here)
library(rstan)
library(dplyr)
library(ggplot2)
library(digest)

util <- new.env()
source(here('src', 'codebase', 'stan_utility.R'), local=util)
rstan_options(auto_write = TRUE)
options(mc.cores=parallel::detectCores())

load(here('md_lane.RData'))
input_data <- list("y" = md_half$Lane.Position - mean(md_half$Lane.Position),
                   "texting" = as.integer(md_half$Stimulus),
                   "N" = length(md_half$Lane.Position),
                   "N_texting" = length(unique(as.integer(md_half$Stimulus))))
colors <- list(c_light=c("#DCBCBC"), c_light_highlight=c("#C79999"),
               c_mid=c("#B97C7C"),   c_mid_highlight=c("#A25050"),
               c_dark=c("#8F2727"),  c_dark_highlight=c("#7C0000"),
               d_light=c("#BCBCDC"), d_light_highlight=c("#9999C7"),
               d_mid=c("#7C7CB9"),   d_mid_highlight=c("#5050A2"),
               d_dark=c("#27278F"),  d_dark_highlight=c("#00007c"))
```

```{r data_plot}
ggplot(md_half, aes(Distance, Lane.Position)) +
    geom_line() +
    geom_point(aes(colour=Stimulus), size=1.5) +
    theme_bw() + 
    theme(legend.position = "bottom",
          legend.background = element_rect(fill="gray90", size=.5, linetype="dotted")) + 
    ggtitle("Texting Driving") +
    xlab("Distance (m)") + 
    ylab("Lane Position(m)") +
    coord_cartesian(ylim=c(1.5, 2.5)) +
    scale_color_manual(labels=c("No Distraction", "Texting"),
                       values=c(colors$c_mid_highlight, colors$d_mid_highlight))
```

# 1. Conceptual Analysis
AR process is intended to have exponential decay but there exists some ringing of behavior in the later lags, a more flexible model architecture is needed to account for this behavior. The stochastic volatility model has more parameters to fit the lags that exhibit the longer frequency trend. There are two states of volatility of interest: mean volatility during normal driving and texting driving.

# 2. Define observations
```{r obs}
writeLines(readLines(here("src", "stan", "sv2.stan"), n=6))
```

# 3. Summary statistics
Correlogram of variances, histogram of variance

# 4. Build generative model
```{r generative_model}
writeLines(readLines(here("src", "stan", "gen_sv2.stan")))
```

```{r model}
writeLines(readLines(here("src", "stan", "sv2.stan")))
```

# 5. Analyze generative ensemble

```{r generate_ensemble, results="hide"}
R <- 1000;
simu_data <- list("N" = input_data$N,
                  "texting" = input_data$texting,
                  "N_texting" = input_data$N_texting)
fit <- stan(here("src", "stan", "gen_sv2.stan"), 
            data=simu_data, iter=R, warmup=0, chains=1, refresh=R, seed=234987,
            algorithm="Fixed_param")
simu_mus <- extract(fit)$mu
simu_phis <- extract(fit)$phi
simu_sigmas <- extract(fit)$sigma
simu_deltas <- extract(fit)$delta_texting
simu_hs <- extract(fit)$h
simu_ys <- extract(fit)$y
hash <- sha1(c(readLines(here("src", "stan", "gen_sv2.stan")),
               readLines(here("src", "stan", "sv2.stan")), 
               as.character(R)))
```

```{r prior_predictive}
png(filename=here("src", "presentation", "graphics", "prior", "sv2.png"),
    width=800, height=600)
probs <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
# prior predictive time series
post <- as.matrix(fit)
sel <- grep("y", colnames(post))
ci50 <- matrix(NA, nrow = length(sel), ncol = 2)
ci90 <- matrix(NA, nrow = length(sel), ncol = 2)
for (i in 1:length(sel)) {
  ci50[i,] <- quantile(post[,sel[i]], prob = c(0.25, 0.75), names = FALSE)
  ci90[i,] <- quantile(post[,sel[i]], prob = c(0.05, 0.95), names = FALSE)
}

plot(0, type= "n", 
     xlim = c(0,length(input_data$y)), ylim = c(-4, 4),
     xlab = "Distance", ylab = "Lane Position (mean corrected)",
     main = "Prior Predictive Lane Positioning")
t <- 1:input_data$N
polygon(c(rev(t), t), c(rev(ci90[,1]), ci90[,2]), col = colors$c_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[,1]), ci50[,2]), col = colors$c_mid, border = FALSE)
t <- which(input_data$texting==2)
polygon(c(rev(t), t), c(rev(ci90[t,1]), ci90[t,2]), col = colors$d_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[t,1]), ci50[t,2]), col = colors$d_mid, border = FALSE)
legend("bottomright", c("50% Interval", "90% Interval"),
       col = c(colors$c_light, colors$d_mid),
       lwd = c(2,2,2), text.font=0.5)
dev.off()
```

**Fit the simulated observations and evaluate
```{r fit_sim_obs}
if(!file.exists(here("data", "generative_fits", hash))) {
  tryCatch({
    registerDoParallel(makeCluster(detectCores()))
  
    simu_list <- t(data.matrix(data.frame(simu_mus, simu_phis, simu_sigmas, simu_deltas, simu_ys)))
  
    # Compile the posterior fit model
    fit_model = stan_model(here('src', 'stan', 'sv2.stan'))
  
    ensemble_output <- foreach(simu=simu_list, .combine='cbind') %dopar% {
      simu_mu <- simu[1]
      simu_phi <- simu[2]
      simu_sigma <- simu[3]
      simu_delta <- simu[4]
      simu_y <- simu[5:(input_data$N + 4)]
      
      # Fit the simulated observation
      sim_data <- list("y" = simu_y, 
                       "N" = length(simu_y), 
                       "N_texting" = input_data$N_texting, 
                       "texting" = input_data$texting)
      capture.output(library(rstan))
      capture.output(
        fit <- sampling(fit_model, 
                        data=sim_data, 
                        seed=4938483,
                        control = list(adapt_delta = 0.8))
        )
      # Compute diagnostics
      util <- new.env()
      source(here::here('src', 'codebase', 'stan_utility.R'), local=util)
  
      warning_code <- util$check_all_diagnostics(fit, quiet=TRUE)
  
      # Compute rank of prior draw with respect to thinned posterior draws
      sbc_rank_mu <- sum(simu_mu < extract(fit)$mu[seq(1, 4000 - 8, 8)])
      sbc_rank_phi <- sum(simu_phi < extract(fit)$phi[seq(1, 4000 - 8, 8)])
      sbc_rank_sigma <- sum(simu_sigma < extract(fit)$sigma[seq(1, 4000 - 8, 8)])
      sbc_rank_delta <- sum(simu_delta < extract(fit)$delta_texting[seq(1, 4000 - 8, 8)])
  
      # Compute posterior sensitivities
      s <- summary(fit, probs = c(), pars='mu')$summary
      post_mean_mu <- s[,1]
      post_sd_mu <- s[,3]
      prior_sd_mu <- 1
      z_score_mu <- abs((post_mean_mu - simu_mu) / post_sd_mu)
      shrinkage_mu <- 1 - (post_sd_mu / prior_sd_mu)**2
  
      s <- summary(fit, probs = c(), pars='phi')$summary
      post_mean_phi <- s[,1]
      post_sd_phi <- s[,3]
      prior_sd_phi <- sqrt(1/12 * (1 - -1)^2)
      z_score_phi <- abs((post_mean_phi - simu_phi) / post_sd_phi)
      shrinkage_phi <- 1 - (post_sd_phi / prior_sd_phi)**2
  
      s <- summary(fit, probs = c(), pars='sigma')$summary
      post_mean_sigma <- s[,1]
      post_sd_sigma <- s[,3]
      prior_sd_sigma <- 1 * (1 - 2 / pi)
      z_score_sigma <- abs((post_mean_sigma- simu_sigma) / post_sd_sigma)
      shrinkage_sigma <- 1 - (post_sd_sigma / prior_sd_sigma)**2
      
      s <- summary(fit, probs = c(), pars='delta_texting')$summary
      post_mean_delta <- s[,1]
      post_sd_delta <- s[,3]
      prior_sd_delta <- 0.05
      z_score_delta <- abs((post_mean_delta - simu_delta) / post_sd_delta)
      shrinkage_delta <- 1 - (post_sd_delta/ prior_sd_delta)**2
      
      c(warning_code,
        sbc_rank_mu, z_score_mu, shrinkage_mu,
        sbc_rank_phi, z_score_phi, shrinkage_phi,
        sbc_rank_sigma, z_score_sigma, shrinkage_sigma,
        sbc_rank_delta, z_score_delta, shrinkage_delta)
      }
    save(ensemble_output, file=here("data", "generative_fits", hash))
  }, finally={ stopImplicitCluster() })
} else {
  load(here("data", "generative_fits", hash)) 
}
```

```{r warning_codes}
warning_code <- ensemble_output[1,]
if (sum(warning_code) != 0) {
  print ("Some simulated posterior fits in the generative ensemble encountered problems!")
  warning_code_df %>% group_by(warning_code) %>% summarize(counts = n())
} else {
  print ("No posterior fits in the generative ensemble encountered problems!")
}
```

```{r sbc}
par(mfrow=c(1, 4))
sbc_rank <- ensemble_output[2,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (mu)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)

sbc_rank <- ensemble_output[5,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (phi)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)

sbc_rank <- ensemble_output[8,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (sigma)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)

sbc_rank <- ensemble_output[11,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (delta)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=colors$c_dark, border=colors$c_dark_highlight, add=T)
```

```{r zscore_shrinkage}
par(mfrow = c(1, 4))
# mu
z_score <- ensemble_output[3,]
shrinkage <- ensemble_output[4,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, main="Mu",
     xlim=c(0, 1), xlab="Posterior Shrinkage", ylim=c(0, 5), ylab="Posterior z-Score")
# phi
z_score <- ensemble_output[6,]
shrinkage <- ensemble_output[7,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, main="Phi",
     xlim=c(0, 1), xlab="Posterior Shrinkage", ylim=c(0, 5), ylab="Posterior z-Score")
# sigma
z_score <- ensemble_output[9,]
shrinkage <- ensemble_output[10,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, main="Sigma",
     xlim=c(0, 1), xlab="Posterior Shrinkage", ylim=c(0, 5), ylab="Posterior z-Score")
# delta
z_score <- ensemble_output[12,]
shrinkage <- ensemble_output[13,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, main="Delta",
     xlim=c(0, 1), xlab="Posterior Shrinkage", ylim=c(0, 5), ylab="Posterior z-Score")
par(mfrow = c(1, 1))
```

# 6. Fit observations and evaluate
```{r actual_fit}
fit <- stan(file=here('src', 'stan', 'sv2.stan'), data=input_data, seed=4938483, refresh=2000)
pairs(fit, pars=c("mu", "sigma", "phi", "delta_texting"))
plot(fit, pars=c("mu", "sigma", "phi", "delta_texting"))
saveRDS(fit, file=here("etc", "results", "sv2.rds"))
```

# 7. Analyze posterior predictive distribution
