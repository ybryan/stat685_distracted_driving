---
title: "Univariate Stochastic Volatility Model with Texting and Not Texting"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cahce = TRUE)

library(here)
library(rstan)
library(foreach)
library(doParallel)
library(dplyr)
library(ggplot2)

util <- new.env()
source(here('src', 'codebase', 'stan_utility.R'), local=util)
rstan_options(auto_write = TRUE)

load(here('md_lane.RData'))
input_data <- list("y" = md_half$Lane.Position - mean(md_half$Lane.Position),
                   "texting" = as.integer(md_half$Stimulus),
                   "T" = length(md_half$Lane.Position),
                   "N_texting" = length(unique(as.integer(md_half$Stimulus))))

# colors
c_light <- c("#DCBCBC")
c_light_highlight <- c("#C79999")
c_mid <- c("#B97C7C")
c_mid_highlight <- c("#A25050")
c_dark <- c("#8F2727")
c_dark_highlight <- c("#7C0000")
d_light <- c("#BCBCDC")
d_light_highlight <- c("#9999C7")
d_mid <- c("#7C7CB9")
d_mid_highlight <- c("#5050A2")
d_dark <- c("#27278F")
d_dark_highlight <- c("#00007c")
```

```{r data_plot}
ggplot(md_half, aes(Distance, Lane.Position)) +
    geom_line() +
    geom_point(aes(colour=Stimulus), size=0.5) +
    theme_bw() + 
    theme(legend.position = "bottom") + 
    ggtitle("Texting Driving") +
    xlab("Distance (m)") + 
    ylab("Lane Position(m)") +
    coord_cartesian(ylim=c(1.5, 2.5)) +
    scale_color_hue(labels=c("None", "Texting"))
```

# 1. Conceptual Analysis
AR process is intended to have exponential decay but there exists some ringing of behavior in the later lags, a more flexible model architecture is needed to account for this behavior. The stochastic volatility model has more parameters to fit the lags that exhibit the longer frequency trend. There are two states of volatility of interest: mean volatility during normal driving and texting driving.

# 2. Define observations
```{r obs}
writeLines(readLines(here("src", "stan", "sv2.stan"), n=6))
```

# 3. Summary statistics
Correlogram of variances, histogram of variance

# 4. Build generative model
```{r generative_model}
writeLines(readLines(here("src", "stan", "gen_sv2.stan")))
```

```{r model}
writeLines(readLines(here("src", "stan", "sv2.stan")))
```

# 5. Analyze generative ensemble
```{r generate_ensemble, results="hide"}
R <- 100;
simu_data <- list("T" = input_data$T,
                  "texting" = input_data$texting,
                  "N_texting" = input_data$N_texting)
fit <- stan(here("src", "stan", "gen_sv2.stan"), 
            data=simu_data, iter=R, warmup=0, chains=1, refresh=R, seed=234987,
            algorithm="Fixed_param")
simu_mus <- extract(fit)$mu
simu_phis <- extract(fit)$phi
simu_sigmas <- extract(fit)$sigma
simu_deltas <- extract(fit)$delta_texting
simu_hs <- extract(fit)$h
simu_ys <- extract(fit)$y
```

```{r prior_predictive_corr}
par(mfrow = c(1, 2), cex=0.8)
probs <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
# prior predictive time series
post <- as.matrix(fit)
sel <- grep("y", colnames(post))
ci50 <- matrix(NA, nrow = length(sel), ncol = 2)
ci90 <- matrix(NA, nrow = length(sel), ncol = 2)
for (i in 1:length(sel)) {
  ci50[i,] <- quantile(post[,sel[i]], prob = c(0.25, 0.75), names = FALSE)
  ci90[i,] <- quantile(post[,sel[i]], prob = c(0.05, 0.95), names = FALSE)
}

plot(0, type= "n", 
     xlim = c(0,length(input_data$y)), ylim = c(-4, 4),
     xlab = "Distance", ylab = "Lane Position (mean corrected)", main = "Prior Predictive\n Lane Positioning")
t <- 1:input_data$T
polygon(c(rev(t), t), c(rev(ci90[,1]), ci90[,2]), col = c_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[,1]), ci50[,2]), col = c_mid, border = FALSE)
t <- which(input_data$texting==2)
polygon(c(rev(t), t), c(rev(ci90[t,1]), ci90[t,2]), col = d_light, border = FALSE)
polygon(c(rev(t), t), c(rev(ci50[t,1]), ci50[t,2]), col = d_mid, border = FALSE)


# correlogram of log variances
B <- 23
counts <- sapply(1:R, function(r) acf(simu_hs[r,], plot=FALSE)$acf)
cred <- sapply(1:B, function(b) quantile(counts[b, ], probs=probs))
idx <- rep(1:B, each=2)
x <- sapply(1:length(idx), function(b) if(b %% 2 == 0) idx[b] + 0.5 else idx[b] - 0.5) - 1
pad_cred <- do.call(cbind, lapply(idx, function(n) cred[1:9, n]))

plot(1, type="n", main="Prior Predictive Correlogram\nLog variances", 
     xlim=c(0.5, B + 0.5), xlab="y", ylim=c(min(cred[1,]), max(cred[9,])), ylab="")
polygon(c(x, rev(x)), c(pad_cred[1,], rev(pad_cred[9,])), col = c_light, border = NA)
polygon(c(x, rev(x)), c(pad_cred[2,], rev(pad_cred[8,])), col = c_light_highlight, border = NA)
polygon(c(x, rev(x)), c(pad_cred[3,], rev(pad_cred[7,])), col = c_mid, border = NA)
polygon(c(x, rev(x)), c(pad_cred[4,], rev(pad_cred[6,])), col = c_mid_highlight, border = NA)
lines(x, pad_cred[5,], col=c_dark, lwd=2)
rm(B, counts, cred, idx, x, pad_cred, probs)
par(mfrow = c(1, 1))
```

**Fit the simulated observations and evaluate
```{r fit_sim_obs}
tryCatch({
  registerDoParallel(makeCluster(detectCores()))

  simu_list <- t(data.matrix(data.frame(simu_mus, simu_phis, simu_sigmas, simu_alphas, simu_ys)))

  # Compile the posterior fit model
  fit_model = stan_model(here('src', 'stan', 'sv2.stan'))

  ensemble_output <- foreach(simu=simu_list,
                             .combine='cbind') %dopar% {
    simu_mu <- simu[1]
    simu_phi <- simu[2]
    simu_sigma <- simu[3]
    simu_alpha_1 <- simu[4]
    simu_alpha_2 <- simu[5]
    simu_y <- simu[6:(N + 5)]
    
    # Fit the simulated observation
    sim_data <- list("y" = simu_y, 
                     "N" = N, 
                     "N_texting" = input_data$N_texting, 
                     "texting" = input_data$texting)
    capture.output(library(rstan))
    capture.output(fit <- sampling(fit_model, data=sim_data, seed=4938483,
                                   control = list(adapt_delta = 0.8)))

    # Compute diagnostics
    util <- new.env()
    source(here::here('src', 'codebase', 'stan_utility.R'), local=util)

    warning_code <- util$check_all_diagnostics(fit, quiet=TRUE)

    # Compute rank of prior draw with respect to thinned posterior draws
    sbc_rank_mu <- sum(simu_mu < extract(fit)$mu[seq(1, 4000 - 8, 8)])
    sbc_rank_phi <- sum(simu_phi < extract(fit)$phi[seq(1, 4000 - 8, 8)])
    sbc_rank_sigma <- sum(simu_sigma < extract(fit)$sigma[seq(1, 4000 - 8, 8)])
    sbc_rank_alpha_1 <- sum(simu_alpha_1 < extract(fit)$alpha_texting[seq(1, 4000 - 8, 8), 1])
    sbc_rank_alpha_2 <- sum(simu_alpha_2 < extract(fit)$alpha_texting[seq(1, 4000 - 8, 8), 2])

    # Compute posterior sensitivities
    s <- summary(fit, probs = c(), pars='mu')$summary
    post_mean_mu <- s[,1]
    post_sd_mu <- s[,3]
    prior_sd_mu <- 1
    z_score_mu <- abs((post_mean_mu - simu_mu) / post_sd_mu)
    shrinkage_mu<- 1 - (post_sd_mu / prior_sd_mu)**2

    s <- summary(fit, probs = c(), pars='phi')$summary
    post_mean_phi <- s[,1]
    post_sd_phi <- s[,3]
    prior_sd_phi <- sqrt(1/12 * (1 - -1)^2)
    z_score_phi <- abs((post_mean_phi - simu_phi) / post_sd_phi)
    shrinkage_phi <- 1 - (post_sd_phi / prior_sd_phi)**2

    s <- summary(fit, probs = c(), pars='sigma')$summary
    post_mean_sigma <- s[,1]
    post_sd_sigma <- s[,3]
    prior_sd_sigma <- 1 * (1 - 2 / pi)
    z_score_sigma <- abs((post_mean_sigma- simu_sigma) / post_sd_sigma)
    shrinkage_sigma <- 1 - (post_sd_sigma / prior_sd_sigma)**2
    
    s <- summary(fit, probs = c(), pars='delta_texting')$summary
    post_mean_delta <- s[,1]
    post_sd_delta <- s[,3]
    prior_sd_delta <- 0.05
    z_score_delta <- abs((post_mean_delta - simu_delta) / post_sd_delta)
    shrinkage_delta<- 1 - (post_sd_delta/ prior_sd_delta)**2
    
    c(warning_code,
      sbc_rank_mu, z_score_mu, shrinkage_mu,
      sbc_rank_phi, z_score_phi, shrinkage_phi,
      sbc_rank_sigma, z_score_sigma, shrinkage_sigma,
      sbc_rank_delta, z_score_delta, shrinkage_delta)
  }
}, finally={ stopImplicitCluster() })
```

```{r warning_codes}
warning_code <- ensemble_output[1,]
if (sum(warning_code) != 0) {
  print ("Some simulated posterior fits in the generative ensemble encountered problems!")
  for (r in 1:R) {
    if (warning_code[r] != 0) {
      print(sprintf('Replication %s of %s', r, R))
      util$parse_warning_code(warning_code[r])
      print(sprintf('Simulated mu = %s', simu_mus[r]))
      print(sprintf('Simulated phi = %s', simu_phis[r]))
      print(sprintf('Simulated sigma = %s', simu_sigmas[r]))
      print(" ")
    }
  }
} else {
  print ("No posterior fits in the generative ensemble encountered problems!")
}
```

```{r sbc}
par(mfrow=c(1, 3))
sbc_rank <- ensemble_output[2,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (mu)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=c_dark, border=c_dark_highlight, add=T)

sbc_rank <- ensemble_output[5,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (phi)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=c_dark, border=c_dark_highlight, add=T)

sbc_rank <- ensemble_output[8,]
sbc_hist <- hist(sbc_rank, seq(0, 500, 25) - 0.5, plot=FALSE)
plot(sbc_hist, main="", xlab="Prior Rank (sigma)", yaxt='n', ylab="")
low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510, -10, 0, -10)
bar_y <- c(high, high, mid, low, low, mid, high)
polygon(bar_x, bar_y, col=c("#DDDDDD"), border=NA)
segments(x0=0, x1=500, y0=mid, y1=mid, col=c("#999999"), lwd=2)
plot(sbc_hist, col=c_dark, border=c_dark_highlight, add=T)
```

```{r zscore_shrinkage}
# mu
z_score <- ensemble_output[3,]
shrinkage <- ensemble_output[4,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, main="Mu",
     xlim=c(0, 1), xlab="Posterior Shrinkage", ylim=c(0, 5), ylab="Posterior z-Score")
# phi
z_score <- ensemble_output[6,]
shrinkage <- ensemble_output[7,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, main="Phi",
     xlim=c(0, 1), xlab="Posterior Shrinkage", ylim=c(0, 5), ylab="Posterior z-Score")
# sigma
z_score <- ensemble_output[9,]
shrinkage <- ensemble_output[10,]
plot(shrinkage, z_score, col=c("#8F272720"), lwd=2, pch=16, cex=0.8, main="Sigma",
     xlim=c(0, 1), xlab="Posterior Shrinkage", ylim=c(0, 5), ylab="Posterior z-Score")
```

# 6. Fit observations and evaluate
```{r actual_fit}
fit <- stan(file=here('src', 'stan', 'sv2.stan'), data=input_data, seed=4938483, refresh=2000)
pairs(fit, pars=c("mu", "sigma", "phi"))
```

# 7. Analyze posterior predictive distribution
